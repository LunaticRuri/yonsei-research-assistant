from fastapi import FastAPI, Depends, HTTPException
from pydantic import BaseModel
from openai import OpenAI
import os
import sys
from dotenv import load_dotenv
from contextlib import asynccontextmanager # [New] ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ ì²˜ë¦¬ìš©

# [!] ê²½ë¡œ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
sys.path.append(os.path.abspath('services'))
sys.path.append(os.path.abspath('../shared'))
sys.path.append(os.path.abspath('..'))

# .env ë¡œë“œ
try:
    load_dotenv(dotenv_path='../.env')
except Exception as e:
    print(f"[ê²½ê³ ] .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")

# [New] ìš°ë¦¬ê°€ ë§Œë“  ê²€ìƒ‰ì–´ ìƒì„±ê¸° ì„í¬íŠ¸
from core.generator import QueryTranslationService
# ê¸°ì¡´ ë¼ìš°íŒ… ì„œë¹„ìŠ¤ ì„í¬íŠ¸
from services.routing_service import get_routing_decision
from shared.models import RoutingDecision

# --- [í•µì‹¬] Lifespan(ìˆ˜ëª…ì£¼ê¸°) ì„¤ì •: ì„œë²„ ì¼¤ ë•Œ ëª¨ë¸ ë¡œë”© ---
translation_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    # 1. ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰: ëª¨ë¸ ë¡œë“œ
    global translation_service
    print("ğŸš€ [System] Strategy Service ì‹œì‘! LoRA ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    
    # ëª¨ë¸ ê²½ë¡œ (GitHub êµ¬ì¡°ì— ë§ì¶¤)
    ADAPTER_PATH = "./models/query_translation_adapter_final"
    translation_service = QueryTranslationService(adapter_path=ADAPTER_PATH)
    
    yield # ì—¬ê¸°ì„œë¶€í„° ì„œë²„ê°€ ì‹¤ì œ ë™ì‘í•¨
    
    # 2. ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ (í•„ìš”í•˜ë©´ ì •ë¦¬ ì‘ì—…)
    print("ğŸ‘‹ [System] Strategy Service ì¢…ë£Œ.")

# ì•± ìƒì„± (lifespan ì ìš©)
app = FastAPI(lifespan=lifespan)

# --- ì˜ì¡´ì„± ì£¼ì… ---
def get_llm_client():
    try:
        return OpenAI() # í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì‚¬ìš©
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì—ëŸ¬: {e}")

# --- DTO (ë°ì´í„° ì „ì†¡ ê°ì²´) ì •ì˜ ---

class QueryRequest(BaseModel):
    """ê¸°ì¡´ ë¼ìš°íŒ… ìš”ì²­ìš©"""
    query: str

class KeywordRequest(BaseModel):
    """[New] í‚¤ì›Œë“œ ìƒì„± ìš”ì²­ìš© (A/B í…ŒìŠ¤íŠ¸ ì§€ì›)"""
    query: str
    mode: str = "api" # ê¸°ë³¸ê°’ì€ api ("api" or "lora")

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/")
def read_root():
    return {"message": "Strategy Service (Routing & Query Translation) is Running!"}

# 1. ë¼ìš°íŒ… ì—”ë“œí¬ì¸íŠ¸ (ê¸°ì¡´)
@app.post("/api/v1/strategy/route", response_model=RoutingDecision)
async def route_query(
    request: QueryRequest,
    llm_client: OpenAI = Depends(get_llm_client)
):
    print(f"â–¶ ë¼ìš°íŒ… ìš”ì²­: {request.query}")
    decision = await get_routing_decision(request.query, llm_client)
    print(f"  â†³ ê²°ì •: {decision.route}")
    return decision

# 2. [New] í‚¤ì›Œë“œ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ (A/B í…ŒìŠ¤íŠ¸ìš©)
@app.post("/api/v1/strategy/keywords")
async def generate_keywords_api(request: KeywordRequest):
    """
    ì§ˆë¬¸ì„ ë°›ì•„ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    mode='api': GPT-4o ì‚¬ìš©
    mode='lora': ë¡œì»¬ T5-LoRA ëª¨ë¸ ì‚¬ìš©
    """
    print(f"â–¶ í‚¤ì›Œë“œ ìƒì„± ìš”ì²­ ({request.mode}): {request.query}")
    
    if translation_service is None:
        raise HTTPException(status_code=500, detail="ë²ˆì—­ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # core/generator.pyì˜ ë¡œì§ ì‹¤í–‰
    result = translation_service.generate_keywords(request.query, mode=request.mode)
    
    print(f"  â†³ ê²°ê³¼: {result['keywords']} ({result['latency_ms']}ms)")
    return result