from fastapi import FastAPI, Depends, HTTPException
from pydantic import BaseModel
from openai import OpenAI
import os
import sys
from dotenv import load_dotenv
from contextlib import asynccontextmanager

# [!] ê²½ë¡œ ì„¤ì • (ì–´ë””ì„œ ì‹¤í–‰í•˜ë“  í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì¡ê¸°)
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.abspath(os.path.join(current_dir, 'services')))
sys.path.append(os.path.abspath(os.path.join(current_dir, '../shared')))
sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))

# .env ë¡œë“œ
try:
    load_dotenv(dotenv_path='../.env')
except Exception as e:
    print(f"[ê²½ê³ ] .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

# [New] ê²€ìƒ‰ì–´ ìƒì„±ê¸° ì„í¬íŠ¸ (Factory Pattern ì ìš©ë¨)
from core.generator import QueryTranslationService

# [!] ê¸°ì¡´ ì„œë¹„ìŠ¤/ëª¨ë¸ ì„í¬íŠ¸ (íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜)
try:
    from services.routing_service import get_routing_decision
    from shared.models import RoutingDecision
except ImportError:
    print("âš ï¸ [Warning] ë¼ìš°íŒ… ì„œë¹„ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Mock ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    class RoutingDecision(BaseModel):
        route: str = "search-agent"
        reason: str = "Import Error Mock"
    async def get_routing_decision(q, c):
        return RoutingDecision()

# --- [í•µì‹¬] Lifespan: ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ ---
translation_service = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global translation_service
    print("ğŸš€ [System] Strategy Service ì‹œì‘! LoRA ëª¨ë¸ ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
    
    # ëª¨ë¸ ê²½ë¡œ (GitHub í´ë” êµ¬ì¡° ê¸°ì¤€)
    ADAPTER_PATH = "./models/query_translation_adapter_final"
    translation_service = QueryTranslationService(adapter_path=ADAPTER_PATH)
    
    yield
    print("ğŸ‘‹ [System] Strategy Service ì¢…ë£Œ.")

app = FastAPI(lifespan=lifespan)

# --- ì˜ì¡´ì„± ì£¼ì… ---
def get_llm_client():
    try:
        return OpenAI()
    except:
        return None

# --- DTO Definition ---

class QueryRequest(BaseModel):
    """ê¸°ì¡´ ë¼ìš°íŒ… ìš”ì²­ìš©"""
    query: str

class KeywordRequest(BaseModel):
    """
    [New] í‚¤ì›Œë“œ ìƒì„± ìš”ì²­ìš© (A/B í…ŒìŠ¤íŠ¸ ë° í™•ì¥ ì§€ì›)
    mode: 'openai', 'lora', 'gemini'(ì˜ˆì •) ë“±
    """
    query: str
    mode: str = "openai" # Factory Patternì— ë§ì¶° êµ¬ì²´ì ì¸ ì´ë¦„ ì‚¬ìš©

# --- API Endpoints ---

@app.get("/")
def read_root():
    return {"message": "Strategy Service (Refactored w/ Factory Pattern) is Running!"}

# 1. ë¼ìš°íŒ… ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/v1/strategy/route", response_model=RoutingDecision)
async def route_query(request: QueryRequest, llm_client: OpenAI = Depends(get_llm_client)):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ê²½ë¡œ(Routing)ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    # print(f"â–¶ ë¼ìš°íŒ… ìš”ì²­: {request.query}") # ë¡œê·¸ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬
    decision = await get_routing_decision(request.query, llm_client)
    return decision

# 2. [New] í‚¤ì›Œë“œ ìƒì„± ì—”ë“œí¬ì¸íŠ¸ (A/B Test)
@app.post("/api/v1/strategy/keywords")
async def generate_keywords_api(request: KeywordRequest):
    """
    ì§ˆë¬¸ì„ ë°›ì•„ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (í™•ì¥í˜• êµ¬ì¡° ì ìš©)
    - mode='openai': GPT-4o ì‚¬ìš©
    - mode='lora': ë¡œì»¬ T5-LoRA ëª¨ë¸ ì‚¬ìš©
    - ì¶”í›„ 'gemini', 'upstage' ë“± ì¶”ê°€ ê°€ëŠ¥
    """
    if translation_service is None:
        raise HTTPException(status_code=500, detail="ë²ˆì—­ ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    print(f"â–¶ í‚¤ì›Œë“œ ìš”ì²­ ({request.mode}): {request.query}")
    
    # core/generator.pyì˜ ë¡œì§ ì‹¤í–‰ (Factoryê°€ ì•Œì•„ì„œ ì²˜ë¦¬)
    result = translation_service.generate_keywords(request.query, mode=request.mode)
    
    print(f"  â†³ ê²°ê³¼: {result['keywords']} ({result['latency_ms']}ms)")
    return result
